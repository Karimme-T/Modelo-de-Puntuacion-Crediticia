{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d24d99e-def3-4394-ac9d-b1c54b8c6ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Setup (uncomment next 2 lines if you need to read your CSV) ---\n",
    "# CSV_PATH = \"./your_data.csv\"\n",
    "# df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import List, Tuple\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e256005c-fd1d-4509-8754-dfe2ba2d5c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- Helpers de nettoyage ---\n",
    "_non_num_pat = re.compile(r\"[^0-9\\-\\.,]\")  # garde chiffres, signe, point, virgule\n",
    "\n",
    "def to_numeric_safe(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"Convertit en numérique en retirant les caractères parasites (espaces, _, %, etc.).\"\"\"\n",
    "    s = s.astype(str).str.replace(r\"\\s+\", \"\", regex=True) \\\n",
    "                     .str.replace(\"_\", \"\", regex=False) \\\n",
    "                     .str.replace(\"%\", \"\", regex=False)\n",
    "    s = s.str.replace(_non_num_pat, \"\", regex=True).str.replace(\",\", \".\", regex=False)\n",
    "    # Evite '' -> NaN puis cast en float\n",
    "    s = pd.to_numeric(s.replace({\"\": np.nan, \".\": np.nan, \"-\": np.nan}), errors=\"coerce\")\n",
    "    return s\n",
    "\n",
    "def parse_credit_history_age(col: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Convertit 'X Years Y Months' en nombre total de mois.\n",
    "    Gère les variantes et parasitages simples.\n",
    "    \"\"\"\n",
    "    def _one(x: str) -> float:\n",
    "        if pd.isna(x): return np.nan\n",
    "        x = str(x).lower().replace(\"_\", \" \").replace(\"-\", \" \")\n",
    "        yrs = re.search(r\"(\\d+)\\s*year\", x)\n",
    "        mos = re.search(r\"(\\d+)\\s*month\", x)\n",
    "        y = int(yrs.group(1)) if yrs else 0\n",
    "        m = int(mos.group(1)) if mos else 0\n",
    "        # fallback: si juste un nombre « 123 », on le prend comme mois déjà\n",
    "        if not yrs and not mos:\n",
    "            m_only = re.search(r\"\\d+\", x)\n",
    "            return float(m_only.group(0)) if m_only else np.nan\n",
    "        return float(y * 12 + m)\n",
    "    return col.apply(_one)\n",
    "\n",
    "def normalize_text(col: pd.Series) -> pd.Series:\n",
    "    \"\"\"Nettoie les catégorielles: trim, minuscule, supprime ponctuation légère et underscores.\"\"\"\n",
    "    return (col.astype(str)\n",
    "              .str.strip()\n",
    "              .str.lower()\n",
    "              .str.replace(\"_\", \" \", regex=False)\n",
    "              .str.replace(r\"[!\\|\\.]+\", \"\", regex=True)\n",
    "              .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "              .replace({\"nan\": np.nan, \"none\": np.nan, \"\": np.nan}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90ac27d1-b5cc-4f51-9f62-6a9309d7baea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lecture (plus robuste)\n",
    "df = pd.read_csv(\"train-3.csv\", low_memory=False)\n",
    "\n",
    "# Harmonise les noms de colonnes (trim + retire espaces/underscores doubles)\n",
    "df.columns = (df.columns.str.strip()\n",
    "                        .str.replace(r\"\\s+\", \"_\", regex=True)\n",
    "                        .str.replace(\"__+\", \"_\", regex=True))\n",
    "\n",
    "# 1) Normalisation catégorielles \"texte\"\n",
    "text_like = [\n",
    "    \"Occupation\",\"Type_of_Loan\",\"Payment_Behaviour\",\"Payment_of_Min_Amount\",\n",
    "    \"Credit_Mix\",\"Credit_Score\",\"SSN\",\"Name\",\"Month\",\"Customer_ID\",\"ID\"\n",
    "]\n",
    "for c in [col for col in text_like]:\n",
    "    df[c] = normalize_text(df[c])\n",
    "\n",
    "# 2) Colonnes attendues numériques -> nettoyage dur\n",
    "num_should_be = [\n",
    "    \"Age\",\"Annual_Income\",\"Monthly_Inhand_Salary\",\"Num_Bank_Accounts\",\"Num_Credit_Card\",\n",
    "    \"Interest_Rate\",\"Delay_from_due_date\",\"Num_Credit_Inquiries\",\"Credit_Utilization_Ratio\",\n",
    "    \"Total_EMI_per_month\",\"Amount_invested_monthly\",\"Outstanding_Debt\",\"Monthly_Balance\",\n",
    "    \"Num_of_Loan\",\"Changed_Credit_Limit\"\n",
    "]\n",
    "for c in [col for col in num_should_be]:\n",
    "    df[c] = to_numeric_safe(df[c])\n",
    "\n",
    "# 3) Champ spécial: Credit_History_Age -> mois\n",
    "if \"Credit_History_Age\" in df.columns:\n",
    "    df[\"Credit_History_Age_Months\"] = parse_credit_history_age(df[\"Credit_History_Age\"])\n",
    "    # on peut garder l’original pour debug si tu veux ; sinon:\n",
    "    df.drop(columns=[\"Credit_History_Age\"], inplace=True)\n",
    "\n",
    "# 4) Standardise quelques catégorielles clés\n",
    "if \"Payment_of_Min_Amount\" in df.columns:\n",
    "    df[\"Payment_of_Min_Amount\"] = df[\"Payment_of_Min_Amount\"].replace({\n",
    "        \"yes\":\"yes\",\"y\":\"yes\",\n",
    "        \"no\":\"no\",\"n\":\"no\",\n",
    "        \"nm\":\"no\"  # souvent « Not Mentioned » -> on l'assimile à 'no' ou mets np.nan si tu préfères\n",
    "    })\n",
    "\n",
    "if \"Credit_Mix\" in df.columns:\n",
    "    # garde en texte propre; l’encodage viendra plus tard\n",
    "    df[\"Credit_Mix\"] = df[\"Credit_Mix\"].replace({\n",
    "        \"good\":\"good\",\"standard\":\"standard\",\"bad\":\"bad\"\n",
    "    })\n",
    "\n",
    "if \"Payment_Behaviour\" in df.columns:\n",
    "    # Exemple de simplification légère (retire 'spent', 'avg', etc. si bruit)\n",
    "    df[\"Payment_Behaviour\"] = df[\"Payment_Behaviour\"].str.replace(r\"(spent|avg|high|low)\", \"\", regex=True).str.strip()\n",
    "    df[\"Payment_Behaviour\"] = df[\"Payment_Behaviour\"].replace({\"\": np.nan})\n",
    "\n",
    "# 5) Drop colonnes identifiants / fuites de cible\n",
    "for col in [\"ID\",\"Customer_ID\",\"Name\",\"SSN\",\"Month\"]:\n",
    "    if col in df.columns:\n",
    "        df.drop(columns=[col], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6511f02c-c2fc-4fab-82ce-ca764b59cbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping columns: ['ID', 'Customer_ID', 'Name', 'SSN', 'Month']\n",
      "Detected 6 categorical: ['Occupation', 'Type_of_Loan', 'Num_of_Delayed_Payment', 'Credit_Mix', 'Payment_of_Min_Amount', 'Payment_Behaviour']\n",
      "Detected 16 numerical: ['Age', 'Annual_Income', 'Monthly_Inhand_Salary', 'Num_Bank_Accounts', 'Num_Credit_Card', 'Interest_Rate', 'Num_of_Loan', 'Delay_from_due_date', 'Changed_Credit_Limit', 'Num_Credit_Inquiries'] ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Feature/target split + type inference\n",
    "# -----------------------------\n",
    "X = df.drop(columns=[TARGET])\n",
    "y = df[TARGET]\n",
    "\n",
    "# Infer categorical vs numerical (heuristic: object/category -> categorical;\n",
    "# low-cardinality integers can be categorical too if you want. Here we keep ints as numeric.)\n",
    "cat_cols: List[str] = [c for c in X.columns if X[c].dtype == \"object\"]\n",
    "num_cols: List[str] = [c for c in X.columns if c not in cat_cols]\n",
    "\n",
    "print(f\"Dropping columns: {drop_cols}\")\n",
    "print(f\"Detected {len(cat_cols)} categorical: {cat_cols[:10]}{' ...' if len(cat_cols)>10 else ''}\")\n",
    "print(f\"Detected {len(num_cols)} numerical: {num_cols[:10]}{' ...' if len(num_cols)>10 else ''}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bccba2f8-543d-4b0b-b5f6-056ce7fc9637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 3) Preprocess + Model\n",
    "# -----------------------------\n",
    "num_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "])\n",
    "\n",
    "cat_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer([\n",
    "    (\"num\", num_pipe, num_cols),\n",
    "    (\"cat\", cat_pipe, cat_cols),\n",
    "])\n",
    "\n",
    "clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(128, 64),\n",
    "    activation=\"relu\",\n",
    "    solver=\"adam\",\n",
    "    alpha=1e-4,\n",
    "    batch_size=256,\n",
    "    learning_rate=\"adaptive\",\n",
    "    max_iter=200,\n",
    "    early_stopping=True,\n",
    "    n_iter_no_change=15,\n",
    "    random_state=42,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"prep\", preprocess),\n",
    "    (\"model\", clf),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1febca09-b8cf-428f-8a1c-fd23d28f0c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 numériques / 6 catégorielles\n"
     ]
    }
   ],
   "source": [
    "# Sépare X / y\n",
    "assert \"Credit_Score\" in df.columns, \"La colonne cible 'Credit_Score' est introuvable.\"\n",
    "y = df[\"Credit_Score\"].astype(\"category\")\n",
    "X = df.drop(columns=[\"Credit_Score\"])\n",
    "\n",
    "# Détection robuste des types APRÈS nettoyage\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = [c for c in X.columns if c not in num_cols]\n",
    "print(f\"{len(num_cols)} numériques / {len(cat_cols)} catégorielles\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5481cc37-1bfd-4b87-a4a9-579edf389664",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "cat_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "\n",
    "num_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "preproc = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", num_pipe, num_cols),\n",
    "        (\"cat\", cat_pipe, cat_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    n_jobs=None\n",
    ")\n",
    "\n",
    "clf = Pipeline(steps=[\n",
    "    (\"prep\", preproc),\n",
    "    (\"model\", LogisticRegression(\n",
    "        max_iter=2000,\n",
    "        multi_class=\"multinomial\",\n",
    "        class_weight=\"balanced\",\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8679bc17-dc08-42f6-b2b6-907e21f7bfba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        good       0.51      0.86      0.64      3566\n",
      "        poor       0.74      0.76      0.75      5799\n",
      "    standard       0.86      0.65      0.74     10635\n",
      "\n",
      "    accuracy                           0.72     20000\n",
      "   macro avg       0.70      0.76      0.71     20000\n",
      "weighted avg       0.76      0.72      0.73     20000\n",
      "\n",
      "[[3065   40  461]\n",
      " [ 663 4436  700]\n",
      " [2228 1499 6908]]\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd64007f-e5d6-44f5-96d0-25068ab63ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Évaluation enrichie (multiclass) ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix,\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    balanced_accuracy_score, cohen_kappa_score, roc_auc_score\n",
    ")\n",
    "\n",
    "# Prédictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eba8d27-db08-4ded-ac45-9db83558e269",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Libellés (ordre fixé pour cohérence)\n",
    "labels = sorted(pd.unique(pd.concat([pd.Series(y_test), pd.Series(y_pred)], ignore_index=True)))\n",
    "cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "cm_norm = cm / cm.sum(axis=1, keepdims=True)\n",
    "\n",
    "# --- Métriques globales\n",
    "metrics = {\n",
    "    \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "    \"balanced_accuracy\": balanced_accuracy_score(y_test, y_pred),\n",
    "    \"precision_macro\": precision_score(y_test, y_pred, average=\"macro\", zero_division=0),\n",
    "    \"recall_macro\": recall_score(y_test, y_pred, average=\"macro\", zero_division=0),\n",
    "    \"f1_macro\": f1_score(y_test, y_pred, average=\"macro\", zero_division=0),\n",
    "    \"precision_weighted\": precision_score(y_test, y_pred, average=\"weighted\", zero_division=0),\n",
    "    \"recall_weighted\": recall_score(y_test, y_pred, average=\"weighted\", zero_division=0),\n",
    "    \"f1_weighted\": f1_score(y_test, y_pred, average=\"weighted\", zero_division=0),\n",
    "    \"cohen_kappa\": cohen_kappa_score(y_test, y_pred),\n",
    "}\n",
    "\n",
    "# ROC-AUC macro (si le modèle expose predict_proba)\n",
    "try:\n",
    "    if hasattr(clf, \"predict_proba\"):\n",
    "        proba = clf.predict_proba(X_test)\n",
    "        # Gestion des cibles catégorielles\n",
    "        y_true_idx = pd.Series(y_test).astype(pd.CategoricalDtype(categories=clf.classes_)).cat.codes.values\n",
    "        metrics[\"roc_auc_ovr_macro\"] = roc_auc_score(\n",
    "            y_true_idx,\n",
    "            proba,\n",
    "            multi_class=\"ovr\",\n",
    "            average=\"macro\"\n",
    "        )\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# --- Rapport détaillé par classe en DataFrame\n",
    "report_dict = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "report_df = pd.DataFrame(report_dict).transpose()\n",
    "display(report_df.style.format({\n",
    "    \"precision\": \"{:.3f}\", \"recall\": \"{:.3f}\", \"f1-score\": \"{:.3f}\", \"support\": \"{:.0f}\"\n",
    "}))\n",
    "\n",
    "# --- Tableau des métriques globales\n",
    "metrics_df = pd.DataFrame([metrics]).T.rename(columns={0: \"value\"})\n",
    "display(metrics_df.style.format(\"{:.4f}\"))\n",
    "\n",
    "# --- Matrice de confusion normalisée (%) pour lecture rapide\n",
    "cm_norm_df = pd.DataFrame(cm_norm, index=[f\"true_{l}\" for l in labels], columns=[f\"pred_{l}\" for l in labels])\n",
    "display(cm_norm_df.applymap(lambda x: f\"{x*100:.1f}%\"))\n",
    "\n",
    "# --- Matrice de confusion (image) ---\n",
    "fig, ax = plt.subplots(figsize=(6, 5), dpi=150)\n",
    "im = ax.imshow(cm)  # Ne pas fixer de palette pour respecter ta contrainte\n",
    "ax.set_title(\"Matrice de confusion (comptes)\")\n",
    "ax.set_xticks(np.arange(len(labels)))\n",
    "ax.set_yticks(np.arange(len(labels)))\n",
    "ax.set_xticklabels(labels, rotation=45, ha=\"right\")\n",
    "ax.set_yticklabels(labels)\n",
    "ax.set_xlabel(\"Prédit\")\n",
    "ax.set_ylabel(\"Vrai\")\n",
    "\n",
    "# Annotations des cases\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        ax.text(j, i, int(cm[i, j]), ha=\"center\", va=\"center\")\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ced5039-9d15-437a-9360-abed796fd3da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
